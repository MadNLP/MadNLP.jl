<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Multi-precision · MadNLP.jl</title><meta name="title" content="Multi-precision · MadNLP.jl"/><meta property="og:title" content="Multi-precision · MadNLP.jl"/><meta property="twitter:title" content="Multi-precision · MadNLP.jl"/><meta name="description" content="Documentation for MadNLP.jl."/><meta property="og:description" content="Documentation for MadNLP.jl."/><meta property="twitter:description" content="Documentation for MadNLP.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="MadNLP.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">MadNLP.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../installation/">Installation</a></li><li><a class="tocitem" href="../../quickstart/">Quickstart</a></li><li><a class="tocitem" href="../../options/">Options</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../gpu/">GPU acceleration</a></li><li class="is-active"><a class="tocitem" href>Multi-precision</a><ul class="internal"><li><a class="tocitem" href="#Defining-a-problem-in-arbitrary-precision"><span>Defining a problem in arbitrary precision</span></a></li><li><a class="tocitem" href="#Solving-a-problem-in-Float32"><span>Solving a problem in Float32</span></a></li><li><a class="tocitem" href="#Solving-a-problem-in-Float128"><span>Solving a problem in Float128</span></a></li></ul></li><li><a class="tocitem" href="../warmstart/">Warm-start</a></li><li><a class="tocitem" href="../lbfgs/">LBFGS</a></li><li><a class="tocitem" href="../kktsystem/">Custom KKT system</a></li></ul></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../../man/solver/">IPM solver</a></li><li><a class="tocitem" href="../../man/kkt/">KKT systems</a></li><li><a class="tocitem" href="../../man/linear_solvers/">Linear Solvers</a></li></ul></li><li><span class="tocitem">API Reference</span><ul><li><a class="tocitem" href="../../lib/ipm/">IPM solver</a></li><li><a class="tocitem" href="../../lib/barrier/">Barrier strategies</a></li><li><a class="tocitem" href="../../lib/callbacks/">Callback wrappers</a></li><li><a class="tocitem" href="../../lib/kkt/">KKT systems</a></li><li><a class="tocitem" href="../../lib/linear_solvers/">Linear Solvers</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Multi-precision</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Multi-precision</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/MadNLP/MadNLP.jl/blob/master/docs/src/tutorials/multiprecision.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Running-MadNLP-in-arbitrary-precision"><a class="docs-heading-anchor" href="#Running-MadNLP-in-arbitrary-precision">Running MadNLP in arbitrary precision</a><a id="Running-MadNLP-in-arbitrary-precision-1"></a><a class="docs-heading-anchor-permalink" href="#Running-MadNLP-in-arbitrary-precision" title="Permalink"></a></h1><p>MadNLP is written in pure Julia, and as such support solving optimization problems in arbitrary precision. By default, MadNLP adapts its precision according to the <code>NLPModel</code> passed in input. Most models use <code>Float64</code> (in fact, almost all optimization modelers are implemented using double precision), but for certain applications it can be useful to use arbitrary precision to get more accurate solution.</p><div class="admonition is-info" id="Info-dd396a27f38bbac"><header class="admonition-header">Info<a class="admonition-anchor" href="#Info-dd396a27f38bbac" title="Permalink"></a></header><div class="admonition-body"><p>There exists different packages to instantiate a optimization model in arbitrary precision in Julia. Most of them leverage the flexibility offered by <a href="https://github.com/JuliaSmoothOptimizers/NLPModels.jl">NLPModels.jl</a>. In particular, we recommend:</p><ul><li><a href="https://github.com/JuliaSmoothOptimizers/CUTEst.jl/">CUTEst.jl</a>: supports <code>Float32</code>, <code>Float64</code> and <code>Float128</code>.</li><li><a href="https://github.com/exanauts/ExaModels.jl">ExaModels</a>: supports <code>AbstractFloat</code>.</li></ul></div></div><h2 id="Defining-a-problem-in-arbitrary-precision"><a class="docs-heading-anchor" href="#Defining-a-problem-in-arbitrary-precision">Defining a problem in arbitrary precision</a><a id="Defining-a-problem-in-arbitrary-precision-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-a-problem-in-arbitrary-precision" title="Permalink"></a></h2><p>As a demonstration, we implement the model <a href="https://vanderbei.princeton.edu/ampl/nlmodels/cute/airport.mod">airport</a> from CUTEst using ExaModels. The code writes:</p><pre><code class="language-julia hljs">using ExaModels

function airport_model(T)
    N = 42
    # Data
    r = T[0.09 , 0.3, 0.09, 0.45, 0.5, 0.04, 0.1, 0.02, 0.02, 0.07, 0.4, 0.045, 0.05, 0.056, 0.36, 0.08, 0.07, 0.36, 0.67, 0.38, 0.37, 0.05, 0.4, 0.66, 0.05, 0.07, 0.08, 0.3, 0.31, 0.49, 0.09, 0.46, 0.12, 0.07, 0.07, 0.09, 0.05, 0.13, 0.16, 0.46, 0.25, 0.1]
    cx = T[-6.3, -7.8, -9.0, -7.2, -5.7, -1.9, -3.5, -0.5, 1.4, 4.0, 2.1, 5.5, 5.7, 5.7, 3.8, 5.3, 4.7, 3.3, 0.0, -1.0, -0.4, 4.2, 3.2, 1.7, 3.3, 2.0, 0.7, 0.1, -0.1, -3.5, -4.0, -2.7, -0.5, -2.9, -1.2, -0.4, -0.1, -1.0, -1.7, -2.1, -1.8, 0.0]
    cy = T[8.0, 5.1, 2.0, 2.6, 5.5, 7.1, 5.9, 6.6, 6.1, 5.6, 4.9, 4.7, 4.3, 3.6, 4.1, 3.0, 2.4, 3.0, 4.7, 3.4, 2.3, 1.5, 0.5, -1.7, -2.0, -3.1, -3.5, -2.4, -1.3, 0.0, -1.7, -2.1, -0.4, -2.9, -3.4, -4.3, -5.2, -6.5, -7.5, -6.4, -5.1, 0.0]
    # Wrap all data in a single iterator for ExaModels
    data = [(i, cx[i], cy[i], r[i]) for i in 1:N]
    IJ = [(i, j) for i in 1:N-1 for j in i+1:N]
    # Write model using ExaModels
    core = ExaModels.ExaCore(T)
    x = ExaModels.variable(core, 1:N, lvar = -10.0, uvar=10.0)
    y = ExaModels.variable(core, 1:N, lvar = -10.0, uvar=10.0)
    ExaModels.objective(
        core,
        ((x[i] - x[j])^2 + (y[i] - y[j])^2) for (i, j) in IJ
    )
    ExaModels.constraint(core, (x[i]-dcx)^2 + (y[i] - dcy)^2 - dr for (i, dcx, dcy, dr) in data; lcon=-Inf)
    return ExaModels.ExaModel(core)
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">airport_model (generic function with 1 method)</code></pre><p>The function <code>airport_model</code> takes as input the type used to define the model in ExaModels. For example, <code>ExaCore(Float64)</code> instantiates a model with <code>Float64</code>, whereas <code>ExaCore(Float32)</code> instantiates a model using <code>Float32</code>. Thus, instantiating the instance <code>airport</code> using <code>Float32</code> simply amounts to</p><pre><code class="language-julia hljs">nlp = airport_model(Float32)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">An ExaModel{Float32, Vector{Float32}, ...}

  Problem name: Generic
   All variables: ████████████████████ 84     All constraints: ████████████████████ 42    
            free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                upper: ████████████████████ 42    
         low/upp: ████████████████████ 84             low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
          infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
            nnzh: (-47.06% sparsity)   5250            linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
                                                    nonlinear: ████████████████████ 42    
                                                         nnzj: ( 97.62% sparsity)   84    
                                                     lin_nnzj: (------% sparsity)         
                                                     nln_nnzj: ( 97.62% sparsity)   84    

</code></pre><p>We verify that the model is correctly instantiated using <code>Float32</code>:</p><pre><code class="language-julia hljs">x0 = NLPModels.get_x0(nlp)
println(typeof(x0))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Vector{Float32}</code></pre><h2 id="Solving-a-problem-in-Float32"><a class="docs-heading-anchor" href="#Solving-a-problem-in-Float32">Solving a problem in Float32</a><a id="Solving-a-problem-in-Float32-1"></a><a class="docs-heading-anchor-permalink" href="#Solving-a-problem-in-Float32" title="Permalink"></a></h2><p>Now that we have defined our model in <code>Float32</code>, we solve it using MadNLP. As <code>nlp</code> is using <code>Float32</code>, MadNLP will automatically adjust its internal types to <code>Float32</code> during the instantiation. By default, the convergence tolerance is also adjusted to the input type, such that <code>tol = sqrt(eps(T))</code>. Hence, in our case the tolerance is set automatically to</p><pre><code class="language-julia hljs">tol = sqrt(eps(Float32))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.00034526698f0</code></pre><p>We solve the problem using Lapack as linear solver:</p><pre><code class="language-julia hljs">results = madnlp(nlp; linear_solver=LapackCPUSolver)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">&quot;Execution stats: Optimal Solution Found (tol = 1.0e-03).&quot;</code></pre><div class="admonition is-info" id="Note-c284bfdafb05e2fe"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-c284bfdafb05e2fe" title="Permalink"></a></header><div class="admonition-body"><p>Note that the distribution of Lapack shipped with Julia supports <code>Float32</code>, so here we do not have to worry whether the type is supported by the linear solver. Almost all linear solvers shipped with MadNLP supports <code>Float32</code>.</p></div></div><p>The final solution is</p><pre><code class="language-julia hljs">results.solution</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">84-element Vector{Float32}:
 -6.1042237
 -7.3201675
 -8.7022505
 -6.547783
 -5.1567717
 -1.8469505
 -3.3253756
 -0.49251527
  1.3583232
  3.8234024
  ⋮
 -2.6840556
 -3.1422696
 -4.000223
 -4.9764223
 -6.141531
 -7.106216
 -5.7435718
 -4.6168227
  0.30903557</code></pre><p>and the objective is</p><pre><code class="language-julia hljs">results.objective</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">47952.723f0</code></pre><p>For completeness, we compare with the solution returned when we solve the same problem using <code>Float64</code>:</p><pre><code class="language-julia hljs">nlp_64 = airport_model(Float64)
results_64 = madnlp(nlp_64; linear_solver=LapackCPUSolver)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">&quot;Execution stats: Optimal Solution Found (tol = 1.0e-08).&quot;</code></pre><p>The final objective is now</p><pre><code class="language-julia hljs">results_64.objective</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">47952.701409727124</code></pre><p>As expected when solving an optimization problem with <code>Float32</code>, the relative difference between the two solutions is far from being negligible:</p><pre><code class="language-julia hljs">rel_diff = abs(results.objective - results_64.objective) / results_64.objective</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4.4307249125524247e-7</code></pre><h2 id="Solving-a-problem-in-Float128"><a class="docs-heading-anchor" href="#Solving-a-problem-in-Float128">Solving a problem in Float128</a><a id="Solving-a-problem-in-Float128-1"></a><a class="docs-heading-anchor-permalink" href="#Solving-a-problem-in-Float128" title="Permalink"></a></h2><p>Now, we go in the opposite direction and solve a problem using <code>Float128</code> to get a better accuracy. We start by loading the library <code>Quadmath</code> to work with quadruple precision:</p><pre><code class="language-julia hljs">using Quadmath</code></pre><p>We can instantiate our problem using <code>Float128</code> directly as:</p><pre><code class="language-julia hljs">nlp_128 = airport_model(Float128)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">An ExaModel{Quadmath.Float128, Vector{Quadmath.Float128}, ...}

  Problem name: Generic
   All variables: ████████████████████ 84     All constraints: ████████████████████ 42    
            free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                upper: ████████████████████ 42    
         low/upp: ████████████████████ 84             low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
          infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
            nnzh: (-47.06% sparsity)   5250            linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
                                                    nonlinear: ████████████████████ 42    
                                                         nnzj: ( 97.62% sparsity)   84    
                                                     lin_nnzj: (------% sparsity)         
                                                     nln_nnzj: ( 97.62% sparsity)   84    

</code></pre><div class="admonition is-warning" id="Warning-b9704b0a50d6b432"><header class="admonition-header">Warning<a class="admonition-anchor" href="#Warning-b9704b0a50d6b432" title="Permalink"></a></header><div class="admonition-body"><p>Unfortunately, a few linear solvers support <code>Float128</code> out of the box. Currently, the only solver suporting quadruple in MadNLP is <code>LDLSolver</code>, which implements <a href="https://github.com/JuliaSmoothOptimizers/LDLFactorizations.jl">an LDL factorization in pure Julia</a>. The solver <code>LDLSolver</code> is not adapted to solve large-scale nonconvex nonlinear programs, but works if the problem is small enough (as it is the case here).</p></div></div><p>Replacing the solver by <code>LDLSolver</code>, solving the problem with MadNLP just amounts to</p><pre><code class="language-julia hljs">results_128 = madnlp(nlp_128; linear_solver=LDLSolver)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">&quot;Execution stats: Optimal Solution Found (tol = 1.0e-17).&quot;</code></pre><p>Note that the final tolerance is much lower than before. We get the solution in quadruple precision</p><pre><code class="language-julia hljs">results_128.solution</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">84-element Vector{Quadmath.Float128}:
 -6.10422346779984075324746317637300190e+00
 -7.32016751646112951214547122344744191e+00
 -8.70225021519367902455800396043161132e+00
 -6.54778300598681716679558184769648358e+00
 -5.15677166066576857882792575858440579e+00
 -1.84695048479262641750440403327346213e+00
 -3.32537558953529983731321975183318410e+00
 -4.92515250359083516678377485953970913e-01
  1.35832327690916348435514663903931195e+00
  3.82340248568206791959202066079244177e+00
  ⋮
 -2.68405535104923868206466270293099121e+00
 -3.14226949616395173158877302605268355e+00
 -4.00022305007620456953394893097651818e+00
 -4.97642231990682172164846696875993814e+00
 -6.14153113112896516196594293898607652e+00
 -7.10621611493401363964299609878440189e+00
 -5.74357155980421850420980936002355446e+00
 -4.61682282079019122893368919072475892e+00
  3.09035786082032038293382403877706561e-01</code></pre><p>as well as the final objective:</p><pre><code class="language-julia hljs">results_128.objective</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">4.79527014096219181130758389630855969e+04</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../gpu/">« GPU acceleration</a><a class="docs-footer-nextpage" href="../warmstart/">Warm-start »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Friday 23 January 2026 12:42">Friday 23 January 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
